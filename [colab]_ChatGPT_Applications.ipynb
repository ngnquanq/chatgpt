{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#AI VIET NAM\n",
        "**Nguyen Quoc Thai**"
      ],
      "metadata": {
        "id": "R0cy-KzFPboW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ChatGPT Basic"
      ],
      "metadata": {
        "id": "0psz-GNRPgPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet openai"
      ],
      "metadata": {
        "id": "xskLzn0EA_et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42643659-5b4c-4a57-c734-cb2a98e60b70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import IPython"
      ],
      "metadata": {
        "id": "q9TwEy_rjJ2S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using API that openai provide (https://platform.openai.com/account/api-keys)\n",
        "OPENAI_API_KEY = \"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\"\n",
        "\n",
        "# OPENAI API configuration\n",
        "openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "DtREvkNPjNHy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_open_params(\n",
        "    model=\"text-davinci-003\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\" set openai parameters\"\"\"\n",
        "\n",
        "    openai_params = {}    \n",
        "\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "def get_completion(params, prompt):\n",
        "    \"\"\" GET completion from openai api\"\"\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        engine = params['model'],\n",
        "        prompt = prompt,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "        frequency_penalty = params['frequency_penalty'],\n",
        "        presence_penalty = params['presence_penalty'],\n",
        "    )\n",
        "    return response\n",
        "\n",
        "def print_response(response):\n",
        "    return IPython.display.Markdown(response.choices[0].text)"
      ],
      "metadata": {
        "id": "K6QLmj4Wj2RA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic parameters\n",
        "params = set_open_params()"
      ],
      "metadata": {
        "id": "BueB5GWF-e--"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic example from john wick lollllll\n",
        "prompt = \"Rules. Without them, we would live with the\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "3IWLNdE2j5p0",
        "outputId": "a027646f-d11e-4e34-f99e-44204e233ad6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " chaos that would ensue if everyone did whatever they wanted whenever they wanted.\n\n1. Respect the rights of others.\n2. Obey laws.\n3. Treat others with kindness and courtesy.\n4. Take responsibility for your actions.\n5. Respect public and private property.\n6. Follow directions and rules.\n7. Refrain from using threatening or abusive language.\n8. Use common sense and good judgment.\n9. Be honest and truthful.\n10. Refrain from engaging in dangerous activities."
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ChatGPT using **langchain** library"
      ],
      "metadata": {
        "id": "7MTb66KPPi4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet openai langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHhM_eSrPlnZ",
        "outputId": "82687c35-d60f-4ff4-ffcc-00d7eae4e6fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.9/922.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "CZLDmGFTPr2J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "pGbHgXLbPvhh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "sCKAGi2VP__U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(temperature=0.5)\n",
        "#The temperature parameter in ChatOpenAI controls the randomness of the generated text. \n",
        "#A higher temperature will result in more creative and unpredictable text, while a lower temperature will result in more conservative and predictable text."
      ],
      "metadata": {
        "id": "wDDEaXURPzHc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_INPUT = \"I love programming.\"\n",
        "FINAL_PROMPT = \"\"\"Classify the text into neutral, negative or positive. \n",
        "\n",
        "Text: {user_input}. \n",
        "Sentiment:\"\"\"\n",
        "\n",
        "chat([HumanMessage(content=FINAL_PROMPT.format(user_input=USER_INPUT))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOwTkC9VQdxb",
        "outputId": "46c0be67-c3a6-4939-f898-10988baf9c47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Positive', additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant that can classify the sentiment of input texts. The labels you can use are positive, negative and neutral.\"),\n",
        "    HumanMessage(content=\"Classify the following sentence: I am doing stupid today!\"),\n",
        "]\n",
        "\n",
        "chat(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnI_AZxGQhLB",
        "outputId": "5c316625-a15d-4271-b545-1464c224b52d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The sentiment of the sentence \"I am doing stupid today!\" is negative.', additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You are an AI research assistant. You use a tone that is technical and scientific.\"),\n",
        "    HumanMessage(content=\"Hello, who are you?\"),\n",
        "    AIMessage(content=\"Greeting! I am an AI research assistant. How can I help you today?\"),\n",
        "    HumanMessage(content=\"Can you tell me about the creation of black holes?\")\n",
        "]\n",
        "\n",
        "chat(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVq0nmRDQnoy",
        "outputId": "23449756-ad8d-4243-dc34-8318fe80a528"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Certainly! Black holes are formed when a massive star runs out of fuel and can no longer sustain nuclear fusion reactions in its core. When this happens, the star's core collapses under the force of gravity, causing the outer layers of the star to be expelled in a massive explosion called a supernova. \\n\\nIf the remaining core of the star is more than about three times the mass of the sun, it will continue to collapse until it becomes a point of infinite density and zero volume known as a singularity. This singularity is surrounded by an event horizon, which is the point of no return beyond which anything, including light, is trapped by the black hole's gravity.\\n\\nBlack holes can also be formed through the collision of two neutron stars or through the accretion of matter onto a pre-existing black hole. These processes can create supermassive black holes, which are millions or billions of times more massive than the sun and are found at the centers of most galaxies.\", additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ChatGPT Application"
      ],
      "metadata": {
        "id": "n-lMyggrPCF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.Text Classification"
      ],
      "metadata": {
        "id": "KIquX5Za-tM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Classify the folowing text.\n",
        "Text: I think the food was okay.\n",
        "This text is:\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "zHVt8y0Q-ypk",
        "outputId": "6557ed7f-8724-470b-e8b9-3fffb24b8def"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Opinion"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Classify the folowing text into neutral, negative, postive.\n",
        "Text: I think the food was okay.\n",
        "This text is:\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "gw-HKW-2-9Qy",
        "outputId": "4d7c0054-7942-44bf-94b5-93b50e9994b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Neutral"
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Classify the folowing text into neutral, negative, postive and explain why result is like this.\n",
        "Text: I think the food was okay.\n",
        "This text is:\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "xDAjP2Jb_FvT",
        "outputId": "9eb0f67b-1205-43fd-e691-595869cc7368"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Neutral.\nThe text expresses neither negative nor positive feelings towards the food. The speaker simply states that they think the food was \"okay,\" which can be interpreted as being neither positive nor negative."
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Classify the folowing text into neutral, negative, postive.\n",
        "Text: So bad.\n",
        "This text is: negative.\n",
        "Text: I think the food was okay.\n",
        "This text is:\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "saGXcwoe_WMf",
        "outputId": "34f973a6-af8f-4e4d-d510-3956e826e967"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Neutral."
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.Machine Translation"
      ],
      "metadata": {
        "id": "x6WAN9g3_tei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Translate these sentence from vi to en language.\n",
        "Text: Tôi đang học trí tuệ nhân tạo tại AI VIET NAM.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "3bbKSVAmGJvZ",
        "outputId": "a925763c-69c9-4a40-d449-86c3b5300509"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nTranslation: I am learning Artificial Intelligence at AI VIET NAM."
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"What do these sentences mean in en?\n",
        "Text: Tôi đang học trí tuệ nhân tạo tại AI VIET NAM.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "H4Y60HZWGwh5",
        "outputId": "d317ab78-0ee5-4ac3-82e5-8721462a7a3c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nI am studying Artificial Intelligence at AI VIET NAM."
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Please provide the en translation for these sentences:\n",
        "Text: Tôi đang học trí tuệ nhân tạo tại AI VIET NAM.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "fzaVjQPyHYZ4",
        "outputId": "8628e28b-c831-407b-e897-7e825e0202eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nI am learning Artificial Intelligence at AI VIET NAM."
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Translate these sentence.\n",
        "Text: Trường học.\n",
        "Translated: School. \n",
        "Text: Tôi đang học trí tuệ nhân tạo tại AI VIET NAM.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "UJlVphikLTlB",
        "outputId": "a7b032a8-0700-4d76-8aba-5b5323b3ccd5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Translated: I am learning Artificial Intelligence at AI VIETNAM."
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Translate these sentence.\n",
        "Text: Tôi thích nó.\n",
        "Translated: I like it. \n",
        "Text: Tôi đang học trí tuệ nhân tạo tại AI VIET NAM.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "u-3Ei455HwCa",
        "outputId": "d64d6392-c6f9-4582-d4fe-171c38e45fa7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Translated: I am learning Artificial Intelligence at AI VIET NAM."
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.Question Answering"
      ],
      "metadata": {
        "id": "tVcDOjNBaJes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the following question:\n",
        "Question: Where was President Ho Chi Minh born?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "PRtIbzA3bORM",
        "outputId": "78a0569c-97a6-4510-a1d3-ce13d8b33f3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nAnswer: President Ho Chi Minh was born in a small village called Hoàng Trù in the Nam Định Province of Vietnam."
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the following question:\n",
        "Question: Where was President Ho Chi Minh born?\n",
        "Context: Hồ Chí Minh (Nguyễn Sinh Cung; 19 May 1890 - 2 September 1969), commonly known as Uncle Ho (Bác Hồ), President Ho (Hồ Chủ tịch) and by other aliases and sobriquets, was a Vietnamese revolutionary and statesman. He served as Prime Minister of Vietnam from 1945 to 1955, and as President of Vietnam from 1945 until his death in 1969. Ideologically a Marxist–Leninist, he was the Chairman and First Secretary of the Workers' Party of Vietnam. Hồ Chí Minh was born in Nghệ An province in the French protectorate of Annam.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "veUKQCjIaMcD",
        "outputId": "e2d0a515-8bfb-4252-d4e4-6b93d99c7e8a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nAnswer: Nghệ An province, French protectorate of Annam"
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the following question:\n",
        "Question: What does a drink from narcissus’s spring cause the driker to do?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "YtmSC8I2c9mm",
        "outputId": "d2d0827a-0be1-42e2-f3bb-a628698fe6f8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Answer: A drink from Narcissus's spring is said to cause the drinker to fall in love with their own reflection."
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the following question:\n",
        "Question: What does a drink from narcissus’s spring cause the driker to do?\n",
        "Context: Mercury has awakened Echo, who weeps for Narcisus, and states that a drink from Narcisscus’s spring causes the drinks to “Grow dotingly enamored of themselves.”\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "GNQ8pG7bdFUc",
        "outputId": "9e957f59-cee0-4d76-ae5a-b82342a2cb6a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nA drink from Narcissus's spring causes the drinker to become infatuated with themselves and become self-absorbed."
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the following question:\n",
        "Question: What does photosynthesis produce that helps plants gow?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "T3GCzlIBf_ps",
        "outputId": "c30ccd05-e3e3-4d90-cb92-b37cb9f1eb36"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nAnswer: Photosynthesis produces oxygen that helps plants grow."
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the following question:\n",
        "Question: What does photosynthesis produce that helps plants gow?\n",
        "Cadidate: (A) Water (B) Oxygen  (C) Protein (D) Sugar.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "tkjHHkc2gIEF",
        "outputId": "d17984cd-e784-4e62-bc60-ce2de2218aa7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nAnswer: B) Oxygen"
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the following question:\n",
        "Question: How many gold medals does Vietnam have in SEA Games 2023?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "FL5yNxpqgz7c",
        "outputId": "b6b953d6-ed24-475e-a5c3-0cd7132facb6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nAnswer: Vietnam has not yet won any gold medals in SEA Games 2023."
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the following question:\n",
        "Question: How many gold medals does Vietnam have in SEA Games 2023?\n",
        "Context: Vietnam won 136 gold medals to secure the top spot in the medal tally as the 2023 Southeast Asian (SEA) Games in Cambodia came to the final official day of competition on Tuesday.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "Vjx7dWgShsMn",
        "outputId": "b00b396a-c7e8-4389-9d47-a0905a85b730"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nAnswer: Vietnam has 136 gold medals from the 2023 SEA Games."
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.Coversation (Role Playing)"
      ],
      "metadata": {
        "id": "Aay_5z0PmV_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"This is a conversation between a customer and a polite, helpful customer service agent.\n",
        "Customer: Hi, I'd like a refund for the coffee maker I ordered. Would that be possible?\n",
        "AI: Response from the customer service agent: Hello. Thank you for reaching out to us. Yes,..\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "UaNnYP51mtA3",
        "outputId": "08282a6b-b093-429f-f914-b839577eb079"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "we can definitely process a refund for the coffee maker you purchased. Can I please have your order number and the reason for the refund?"
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
        "Human: Hello, who are you?\n",
        "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
        "Human: Can you tell me about the creation of blackholes?\n",
        "AI:\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "n8KJ1h76mVVO",
        "outputId": "1e7b662b-ee76-4bff-8ea7-429745294c19"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Sure! Black holes are formed when a large star runs out of fuel and collapses inward due to its own gravity. As the star collapses, its gravity increases, and eventually it becomes so strong that not even light can escape. This is referred to as the \"event horizon.\" The result is a black hole, which is an area of space with such strong gravity that nothing, not even light, can escape from it."
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.Reasoning"
      ],
      "metadata": {
        "id": "lzLbC2N10HEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"What is 9,000 * 9,000?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "TabGqy0A0MBE",
        "outputId": "7894dbe9-60a3-46c6-c94b-e5a44d1783ad"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n81,000,000"
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "f4prWEqV03Pf",
        "outputId": "e95f1af6-c1c0-4eb4-a36f-225c8bcdbdef"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nThe odd numbers in this group add up to 117."
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "xgSlhDeu1KnV",
        "outputId": "a9103367-8a29-4e18-b64d-8769c49283ac"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nThe odd numbers in this group add up to 117, which is an even number."
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "CJ--lQIE1SUP",
        "outputId": "0736a926-cbb8-40ce-b232-e11907f2bc9a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nOdd numbers: 15, 5, 13, 7, 1\n\nTotal = 41\n\n41 is an odd number."
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.Coding Applications"
      ],
      "metadata": {
        "id": "pkt6XWjl23iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Write a function that calculates the average of the numbers in Python List.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLIGqsms6X8h",
        "outputId": "e4876739-a7c1-4aa4-96e8-5bed3ceed5b5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "def average(nums):\n",
            "    total = 0\n",
            "    for num in nums:\n",
            "        total += num\n",
            "    return total/len(nums)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Write a function that calculates the average of the numbers in Python List.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sdBEsSG27Wv",
        "outputId": "5f65719f-85d0-4569-e1ff-5a85f765adcf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "def average(numbers):\n",
            "    total = 0\n",
            "    for number in numbers:\n",
            "        total += number\n",
            "    return total / len(numbers)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Write a function that calculates the average of the numbers in a Python List.\n",
        "Add to comment for code\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLYHUdQF5Jtt",
        "outputId": "25d75df5-4e1b-4ec8-ce1f-e2f27540c5df"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "def calculate_average(numbers):\n",
            "    \"\"\"Calculates the average of the numbers in a list.\n",
            "\n",
            "    Args:\n",
            "        numbers (list): A list of numbers\n",
            "\n",
            "    Returns:\n",
            "        float: The average of the numbers\n",
            "    \"\"\"\n",
            "    total = 0\n",
            "\n",
            "    # loop through the list and add each number to the total\n",
            "    for number in numbers:\n",
            "        total += number\n",
            "\n",
            "    # divide the total by the number of elements in the list\n",
            "    average = total / len(numbers)\n",
            "\n",
            "    return average\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Debug this code:\n",
        "def average(nums):\n",
        "  total = 0\n",
        "  for num in nums\n",
        "    total += num\n",
        "  return total/len(nums)\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x79aALL5n9y",
        "outputId": "7065309b-dad0-4c54-940a-a49b76b933f4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#The code should be:\n",
            "def average(nums):\n",
            "  total = 0\n",
            "  for num in nums: #missing a colon\n",
            "    total += num\n",
            "  return total/len(nums)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Debug this code:\n",
        "def average(nums):\n",
        "  total = 0\n",
        "  for num in nums:\n",
        "    total += num\n",
        "  return total*len(nums)\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2YLZc9U54Qh",
        "outputId": "c85b2636-a71c-41d7-dbc0-93bbbb66d57f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#Solution\n",
            "def average(nums):\n",
            "  total = 0\n",
            "  for num in nums:\n",
            "    total += num\n",
            "  return total/len(nums)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ChatGPT Limitations"
      ],
      "metadata": {
        "id": "3vU8qr30tSD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\" \n",
        "Question: When did the world population reach 8 billion people?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOiS0sxptXEu",
        "outputId": "9aa96b9e-e7d4-4332-8c65-259ccb5ba3e6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer: The world population reached 8 billion people in March 2020.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\" \n",
        "Question: How many country names start with the letter V?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZmHCCvQ494a",
        "outputId": "54e2bc91-855a-4896-b5c5-eafa6a97ac48"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer: There are 6 countries that start with the letter V: Vanuatu, Vatican City, Venezuela, Vietnam, Virgin Islands, and the Republic of the Congo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\" \n",
        "Question: Count the number of letters 's' that appear last in each word of the following sentence:\n",
        "Sentence: She sells seashells by the seashore, the shells she sells are surely seashells.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV5inWhl5ZjP",
        "outputId": "7bac73f9-3058-41fc-ff0f-6ae6acbc1808"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer: 5\n"
          ]
        }
      ]
    }
  ]
}